{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b111a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcd_base(X, y, alpha, w, C, tol, it):\n",
    "    D = 0\n",
    "    l = len(y)\n",
    "\n",
    "    for i in range(l):\n",
    "        xi, yi = X[i], y[i]\n",
    "        G = yi * np.dot(w, xi) - 1\n",
    "\n",
    "        if alpha[i] == 0 and G >= 0:\n",
    "            continue\n",
    "        elif 0 < alpha[i] < C and abs(G) < tol:\n",
    "            continue\n",
    "\n",
    "        Qii = np.dot(xi, xi) + D\n",
    "        alpha_i_old = alpha[i]\n",
    "        alpha[i] -= G / Qii\n",
    "        alpha[i] = min(max(alpha[i], 0), C)\n",
    "        w += (alpha[i] - alpha_i_old) * yi * xi\n",
    "\n",
    "    return w, alpha\n",
    "\n",
    "def dcd_random_perm(X, y, alpha, w, C, tol, it):\n",
    "    D = 0\n",
    "    l = len(y)\n",
    "\n",
    "    for i in np.random.permutation(l):\n",
    "        xi, yi = X[i], y[i]\n",
    "        G = yi * np.dot(w, xi) - 1\n",
    "\n",
    "        if alpha[i] == 0 and G >= 0:\n",
    "            continue\n",
    "        elif 0 < alpha[i] < C and abs(G) < tol:\n",
    "            continue\n",
    "\n",
    "        Qii = np.dot(xi, xi) + D\n",
    "        alpha_i_old = alpha[i]\n",
    "        alpha[i] -= G / Qii\n",
    "        alpha[i] = min(max(alpha[i], 0), C)\n",
    "        w += (alpha[i] - alpha_i_old) * yi * xi\n",
    "\n",
    "    return w, alpha\n",
    "\n",
    "def dcd_online(X, y, alpha, w, C, tol, it):\n",
    "    D = 0\n",
    "    l = len(y)\n",
    "\n",
    "    i = np.random.randint(0, l)\n",
    "    xi, yi = X[i], y[i]\n",
    "    G = yi * np.dot(w, xi) - 1\n",
    "\n",
    "    if alpha[i] == 0 and G >= 0:\n",
    "        return w, alpha\n",
    "    elif 0 < alpha[i] < C and abs(G) < tol:\n",
    "        return w, alpha\n",
    "\n",
    "    Qii = np.dot(xi, xi) + D\n",
    "    alpha_i_old = alpha[i]\n",
    "    alpha[i] -= G / Qii\n",
    "    alpha[i] = min(max(alpha[i], 0), C)\n",
    "    w += (alpha[i] - alpha_i_old) * yi * xi\n",
    "\n",
    "    return w, alpha\n",
    "\n",
    "def dcd_with_shrinking(X, y, alpha, w, C, tol, it):\n",
    "    D = 0\n",
    "    l, n = X.shape\n",
    "\n",
    "    if it == 0:\n",
    "        dcd_with_shrinking.active_set = np.ones(l, dtype=bool)\n",
    "        dcd_with_shrinking.shrink_counter = 0\n",
    "\n",
    "    active_set = dcd_with_shrinking.active_set\n",
    "\n",
    "    G_proj = compute_projected_gradient(alpha, X, y, w, D, C)\n",
    "\n",
    "    bar_G = G_proj[active_set].max()\n",
    "    under_G = G_proj[active_set].min()\n",
    "\n",
    "    for i in np.random.permutation(np.where(active_set)[0]):\n",
    "        xi, yi = X[i], y[i]\n",
    "        G = yi * np.dot(w, xi) - 1 \n",
    "\n",
    "        if alpha[i] == 0 and G >= 0:\n",
    "            continue\n",
    "        elif 0 < alpha[i] < C and abs(G) < tol:\n",
    "            continue\n",
    "\n",
    "        Qii = np.dot(xi, xi) + D\n",
    "        alpha_old_i = alpha[i]\n",
    "        alpha[i] -= G / Qii\n",
    "        alpha[i] = min(max(alpha[i], 0), C)\n",
    "        w += (alpha[i] - alpha_old_i) * yi * xi\n",
    "\n",
    "    for i in range(l):\n",
    "        if not active_set[i]:\n",
    "            continue\n",
    "        if alpha[i] == 0 and G_proj[i] > bar_G:\n",
    "            active_set[i] = False\n",
    "        elif alpha[i] == C and G_proj[i] < under_G:\n",
    "            active_set[i] = False\n",
    "\n",
    "    dcd_with_shrinking.shrink_counter += 1\n",
    "    if dcd_with_shrinking.shrink_counter % 10 == 0 or np.sum(active_set) < l * 0.1:\n",
    "        active_set[:] = True\n",
    "\n",
    "    return w, alpha\n",
    "\n",
    "methods_dense = {\n",
    "    \"Base\": dcd_base,\n",
    "    \"Random Permutation\": dcd_random_perm,\n",
    "    \"Online\": dcd_online,\n",
    "    \"With Shrinking\": dcd_with_shrinking\n",
    "}\n",
    "\n",
    "def compute_projected_gradient(alpha, X, y, w, D, C):\n",
    "    G_proj = []\n",
    "    for i in range(len(alpha)):\n",
    "        G = y[i] * np.dot(w, X[i]) - 1\n",
    "        if alpha[i] == 0:\n",
    "            G_proj.append(min(0, G))\n",
    "        elif alpha[i] == C:  \n",
    "            G_proj.append(max(0, G))\n",
    "        else:\n",
    "            G_proj.append(G)\n",
    "    return np.array(G_proj)\n",
    "\n",
    "def dual_objective(alpha, X, y, D):\n",
    "    w = np.dot((alpha * y), X)\n",
    "    loss = 0.5 * np.dot(w, w) - np.sum(alpha)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def kkt_violations(alpha, X, y, w, D, C, tol=1e-3):\n",
    "    violations = 0\n",
    "    for i in range(len(alpha)):\n",
    "        G = y[i] * np.dot(w, X[i]) - 1\n",
    "        if alpha[i] == 0 and G < -tol:\n",
    "            violations += 1\n",
    "        elif 0 < alpha[i] < C and abs(G) > tol:\n",
    "            violations += 1\n",
    "        elif alpha[i] == C and G > tol:\n",
    "            violations += 1\n",
    "    return violations / len(alpha)\n",
    "\n",
    "\n",
    "def primal_gap(w, X, y, C, fP_star):\n",
    "    fP = primal_objective(w, X, y, C)\n",
    "    return abs(fP - fP_star) / abs(fP_star)\n",
    "\n",
    "\n",
    "def primal_objective(w, X, y, C):\n",
    "    margins = 1 - y * (X @ w)\n",
    "    hinge_loss = np.sum(np.maximum(0, margins))\n",
    "    return np.dot(w, w) + C * hinge_loss\n",
    "\n",
    "\n",
    "def evaluate_with_criteria_dense(X, y, methods, C=1.0, tol=1e-3, max_iter=1000):\n",
    "    D = 0\n",
    "    results = []\n",
    "\n",
    "    for name, method in methods.items():\n",
    "        for criterion_name in ['delta_alpha', 'projected_gradient', 'dual_objective']:\n",
    "            alpha = np.zeros(len(y))\n",
    "            w = np.zeros(X.shape[1])\n",
    "            alpha_old = alpha.copy()\n",
    "            f_old = dual_objective(alpha, X, y, D)\n",
    "            convergence_log = [] \n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            for it in range(max_iter):\n",
    "                w, alpha = method(X, y, alpha, w, C, tol, it)\n",
    "\n",
    "                if criterion_name == 'delta_alpha':\n",
    "                    delta = np.linalg.norm(alpha - alpha_old)\n",
    "                    convergence_log.append(delta)\n",
    "                    if delta < tol:\n",
    "                        break\n",
    "                elif criterion_name == 'projected_gradient':\n",
    "                    G_proj = compute_projected_gradient(alpha, X, y, w, D, C)\n",
    "                    gap = G_proj.max() - G_proj.min()\n",
    "                    convergence_log.append(gap)\n",
    "                    if gap < tol:\n",
    "                        break\n",
    "                elif criterion_name == 'dual_objective':\n",
    "                    f_new = dual_objective(alpha, X, y, D)\n",
    "                    diff = abs(f_new - f_old)\n",
    "                    convergence_log.append(diff)\n",
    "                    if diff < tol:\n",
    "                        break\n",
    "                    f_old = f_new\n",
    "\n",
    "                alpha_old = alpha.copy()\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            accuracy = accuracy_score(y, np.sign(X @ w))\n",
    "\n",
    "            kkt_error = kkt_violations(alpha, X, y, w, D, tol)\n",
    "            fP = primal_objective(w, X, y, C)\n",
    "            \n",
    "            results.append({\n",
    "                'Method': name,\n",
    "                'Criterion': criterion_name,\n",
    "                'Time': elapsed,\n",
    "                'Accuracy': accuracy,\n",
    "                'Iterations': it + 1,\n",
    "                'Log': convergence_log,\n",
    "                'KKT_violation': kkt_error,\n",
    "                'fP': fP \n",
    "            })\n",
    "\n",
    "    fP_star = min(res['fP'] for res in results)\n",
    "    for res in results:\n",
    "        res['PrimalGap'] = abs(res['fP'] - fP_star) / abs(fP_star)\n",
    "\n",
    "    return results\n",
    "def display_results_table(results):\n",
    "    df = pd.DataFrame(results)\n",
    "    display(df)\n",
    "\n",
    "def plot_convergence(results):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "    colors = prop_cycle.by_key()['color']\n",
    "    extended_colors = plt.get_cmap('tab20').colors  \n",
    "\n",
    "    for idx, res in enumerate(results):\n",
    "        label = f\"{res['Method']} - {res['Criterion']}\"\n",
    "        iters = list(range(1, len(res['Log']) + 1))\n",
    "        color = extended_colors[idx % len(extended_colors)]  \n",
    "        plt.plot(iters, res['Log'], label=label, color=color, linewidth=2)\n",
    "\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Stopping criterion (log)\")\n",
    "    plt.title(\"Convergence of stopping criteria\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_projected_gradient_s(alpha, X, y, w, D, C):\n",
    "    G = y * X.dot(w) - 1\n",
    "\n",
    "    G_proj = G.copy()\n",
    "\n",
    "    mask_lower = (alpha == 0)\n",
    "    mask_upper = (alpha == C)\n",
    "    mask_middle = (alpha > 0) & (alpha < C)\n",
    "\n",
    "    G_proj[mask_lower] = np.minimum(0, G[mask_lower])\n",
    "    G_proj[mask_upper] = np.maximum(0, G[mask_upper])\n",
    "    G_proj[~(mask_lower | mask_upper | mask_middle)] = 0  \n",
    "\n",
    "    return G_proj\n",
    "\n",
    "def dual_objective_s(alpha, X, y, D):\n",
    "    w = X.T.dot(alpha * y)  \n",
    "\n",
    "    w_norm_sq = np.dot(w, w)\n",
    "\n",
    "    loss = w_norm_sq - np.sum(alpha)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def dcd_base_s(X, y, alpha, w, C, tol, it):\n",
    "    D = 0\n",
    "    l = X.shape[0]\n",
    "\n",
    "    for i in range(l):\n",
    "        xi = X.getrow(i)         \n",
    "        yi = y[i]\n",
    "        G = yi * xi.dot(w).item() - 1  \n",
    "\n",
    "        if alpha[i] == 0 and G >= 0:\n",
    "            continue\n",
    "        elif 0 < alpha[i] < C and abs(G) < tol:\n",
    "            continue\n",
    "\n",
    "        Qii = xi.multiply(xi).sum() + D\n",
    "        alpha_i_old = alpha[i]\n",
    "        alpha[i] -= G / Qii\n",
    "        alpha[i] = min(max(alpha[i], 0), C)\n",
    "\n",
    "        delta_alpha = alpha[i] - alpha_i_old\n",
    "        if delta_alpha != 0:\n",
    "            w[xi.indices] += delta_alpha * yi * xi.data\n",
    "\n",
    "    return w, alpha\n",
    "\n",
    "def dcd_random_perm_s(X, y, alpha, w, C, tol, it):\n",
    "    D = 0\n",
    "    l = X.shape[0]\n",
    "\n",
    "    for i in np.random.permutation(l):\n",
    "        xi = X.getrow(i)  \n",
    "        yi = y[i]\n",
    "        G = yi * xi.dot(w).item() - 1\n",
    "\n",
    "        if alpha[i] == 0 and G >= 0:\n",
    "            continue\n",
    "        elif 0 < alpha[i] < C and abs(G) < tol:\n",
    "            continue\n",
    "\n",
    "        Qii = xi.multiply(xi).sum() + D\n",
    "        alpha_i_old = alpha[i]\n",
    "        alpha[i] -= G / Qii\n",
    "        alpha[i] = min(max(alpha[i], 0), C)\n",
    "\n",
    "        delta_alpha = alpha[i] - alpha_i_old\n",
    "        if delta_alpha != 0:\n",
    "            w[xi.indices] += delta_alpha * yi * xi.data\n",
    "\n",
    "    return w, alpha\n",
    "\n",
    "def dcd_online_s(X, y, alpha, w, C, tol, it):\n",
    "    D = 0\n",
    "    l = X.shape[0]\n",
    "\n",
    "    i = np.random.randint(0, l)\n",
    "    xi = X.getrow(i)  \n",
    "    yi = y[i]\n",
    "\n",
    "    G = yi * xi.dot(w).item() - 1\n",
    "\n",
    "    if alpha[i] == 0 and G >= 0:\n",
    "        return w, alpha\n",
    "    elif 0 < alpha[i] < C and abs(G) < tol:\n",
    "        return w, alpha\n",
    "\n",
    "    Qii = xi.multiply(xi).sum() + D\n",
    "    alpha_i_old = alpha[i]\n",
    "    alpha[i] -= G / Qii\n",
    "    alpha[i] = min(max(alpha[i], 0), C)\n",
    "\n",
    "    delta_alpha = alpha[i] - alpha_i_old\n",
    "    if delta_alpha != 0:\n",
    "        w[xi.indices] += delta_alpha * yi * xi.data\n",
    "\n",
    "    return w, alpha\n",
    "\n",
    "def dcd_with_shrinking_s(X, y, alpha, w, C, tol, it):\n",
    "    D = 0\n",
    "    l = X.shape[0]\n",
    "\n",
    "    if it == 0:\n",
    "        dcd_with_shrinking_s.active_set = np.ones(l, dtype=bool)\n",
    "        dcd_with_shrinking_s.shrink_counter = 0\n",
    "\n",
    "    active_set = dcd_with_shrinking_s.active_set\n",
    "\n",
    "    G_proj = compute_projected_gradient_s(alpha, X, y, w, D, C)\n",
    "\n",
    "    bar_G = G_proj[active_set].max()\n",
    "    under_G = G_proj[active_set].min()\n",
    "\n",
    "    for i in np.random.permutation(np.where(active_set)[0]):\n",
    "        xi = X.getrow(i)\n",
    "        yi = y[i]\n",
    "        G = yi * xi.dot(w).item() - 1\n",
    "\n",
    "        if alpha[i] == 0 and G >= 0:\n",
    "            continue\n",
    "        elif 0 < alpha[i] < C and abs(G) < tol:\n",
    "            continue\n",
    "\n",
    "        Qii = xi.multiply(xi).sum() + D\n",
    "        alpha_old = alpha[i]\n",
    "        alpha[i] -= G / Qii\n",
    "        alpha[i] = min(max(alpha[i], 0), C)\n",
    "\n",
    "        delta_alpha = alpha[i] - alpha_old\n",
    "        if delta_alpha != 0:\n",
    "            w[xi.indices] += delta_alpha * yi * xi.data\n",
    "\n",
    "    for i in range(l):\n",
    "        if not active_set[i]:\n",
    "            continue\n",
    "        if alpha[i] == 0 and G_proj[i] > bar_G:\n",
    "            active_set[i] = False\n",
    "        elif alpha[i] == C and G_proj[i] < under_G:\n",
    "            active_set[i] = False\n",
    "\n",
    "    dcd_with_shrinking_s.shrink_counter += 1\n",
    "    if dcd_with_shrinking_s.shrink_counter % 10 == 0 or np.sum(active_set) < l * 0.1:\n",
    "        active_set[:] = True\n",
    "\n",
    "    return w, alpha\n",
    "\n",
    "def generate_synthetic_dataset(n_samples, n_features, type):\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=50,\n",
    "        n_redundant=0,\n",
    "        n_classes=2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    density = None\n",
    "\n",
    "    if type == 'sparse':\n",
    "        X[np.abs(X) < 5.0] = 0\n",
    "        X = csr_matrix(X)\n",
    "        density = 100 * X.nnz / (X.shape[0] * X.shape[1])\n",
    "\n",
    "    y = 2 * y - 1\n",
    "    return X, y, density\n",
    "\n",
    "def kkt_violations_s(alpha, X, y, w, D, C, tol=1e-3):\n",
    "    violations = 0\n",
    "    l = len(alpha)\n",
    "\n",
    "    for i in range(l):\n",
    "        xi = X.getrow(i)\n",
    "        G = y[i] * xi.dot(w).item() - 1  \n",
    "\n",
    "        if alpha[i] == 0 and G < -tol:\n",
    "            violations += 1\n",
    "        elif 0 < alpha[i] < C and abs(G) > tol:\n",
    "            violations += 1\n",
    "        elif alpha[i] == C and G > tol:\n",
    "            violations += 1\n",
    "\n",
    "    return violations / l\n",
    "\n",
    "def primal_objective_s(w, X, y, C):\n",
    "    margins = 1 - y * X.dot(w)\n",
    "    hinge_loss = np.sum(np.maximum(0, margins))\n",
    "    return np.dot(w, w) + C * hinge_loss\n",
    "\n",
    "def primal_gap_s(w, X, y, C, fP_star):\n",
    "    fP = primal_objective_s(w, X, y, C)\n",
    "    return abs(fP - fP_star) / abs(fP_star)\n",
    "\n",
    "def evaluate_with_criteria_sparse(X, y, methods, C=1.0, tol=1e-3, max_iter=1000):\n",
    "    D = 0\n",
    "    results = []\n",
    "\n",
    "    for name, method in methods.items():\n",
    "        for criterion_name in ['delta_alpha', 'projected_gradient', 'dual_objective']:\n",
    "            alpha = np.zeros(len(y))\n",
    "            w = np.zeros(X.shape[1])\n",
    "            alpha_old = alpha.copy()\n",
    "            f_old = dual_objective_s(alpha, X, y, D)\n",
    "            convergence_log = [] \n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            for it in range(max_iter):\n",
    "                w, alpha = method(X, y, alpha, w, C, tol, it)\n",
    "\n",
    "                if criterion_name == 'delta_alpha':\n",
    "                    delta = np.linalg.norm(alpha - alpha_old)\n",
    "                    convergence_log.append(delta)\n",
    "                    if delta < tol:\n",
    "                        break\n",
    "                elif criterion_name == 'projected_gradient':\n",
    "                    G_proj = compute_projected_gradient_s(alpha, X, y, w, D, C)\n",
    "                    gap = G_proj.max() - G_proj.min()\n",
    "                    convergence_log.append(gap)\n",
    "                    if gap < tol:\n",
    "                        break\n",
    "                elif criterion_name == 'dual_objective':\n",
    "                    f_new = dual_objective_s(alpha, X, y, D)\n",
    "                    diff = abs(f_new - f_old)\n",
    "                    convergence_log.append(diff)\n",
    "                    if diff < tol:\n",
    "                        break\n",
    "                    f_old = f_new\n",
    "\n",
    "                alpha_old = alpha.copy()\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            accuracy = accuracy_score(y, np.sign(X @ w))\n",
    "\n",
    "            kkt_error = kkt_violations_s(alpha, X, y, w, D, C, tol)\n",
    "            fP = primal_objective_s(w, X, y, C)\n",
    "\n",
    "            results.append({\n",
    "                'Method': name,\n",
    "                'Criterion': criterion_name,\n",
    "                'Time': elapsed,\n",
    "                'Accuracy': accuracy,\n",
    "                'Iterations': it + 1,\n",
    "                'Log': convergence_log,\n",
    "                'KKT_violation': kkt_error,\n",
    "                'fP': fP\n",
    "            })\n",
    "\n",
    "    fP_star = min(res['fP'] for res in results)\n",
    "    for res in results:\n",
    "        res['PrimalGap'] = abs(res['fP'] - fP_star) / abs(fP_star)\n",
    "\n",
    "    return results\n",
    "\n",
    "def display_results_table(results):\n",
    "    df = pd.DataFrame(results)\n",
    "    display(df)\n",
    "\n",
    "methods_sparse = {\n",
    "    \"Base\": dcd_base_s,\n",
    "    \"Random Permutation\": dcd_random_perm_s,\n",
    "    \"Online\": dcd_online_s,\n",
    "    \"With Shrinking\": dcd_with_shrinking_s\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c4f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_dataset(n_samples, n_features, n_informative, n_redundant, n_repeated, n_classes, random_state=None, type='dense'):\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,       \n",
    "        n_features=n_features,       \n",
    "        n_informative=n_informative,      \n",
    "        n_redundant=n_redundant,        \n",
    "        n_repeated=n_repeated,         \n",
    "        n_classes=n_classes,          \n",
    "        n_clusters_per_class=2,\n",
    "        weights=[0.5, 0.5],    \n",
    "        flip_y=0.05,          \n",
    "        random_state=random_state, \n",
    "        shuffle=False \n",
    "    )\n",
    "    density = None\n",
    "\n",
    "    if type == 'sparse':\n",
    "        threshold = np.percentile(np.abs(X), 99)\n",
    "        X[np.abs(X) < threshold] = 0\n",
    "        X = csr_matrix(X)\n",
    "        density = 100 * X.nnz / (X.shape[0] * X.shape[1])\n",
    "\n",
    "    y = 2 * y - 1\n",
    "    feature_types = ['informative'] * n_informative + \\\n",
    "                    ['redundant'] * n_redundant + \\\n",
    "                    ['repeated'] * n_repeated + \\\n",
    "                    ['noise'] * (n_features - n_informative - n_redundant - n_repeated)\n",
    "    return X, y, density, feature_types\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense, y_dense, _ = generate_synthetic_dataset(n_samples=1000, n_features=100000, type='dense')\n",
    "\n",
    "X_sparse_raw = X_dense.copy()\n",
    "threshold = np.percentile(np.abs(X_sparse_raw), 99)\n",
    "X_sparse_raw[np.abs(X_sparse_raw) < threshold] = 0\n",
    "X_sparse = csr_matrix(X_sparse_raw)\n",
    "density = 100 * X_sparse.nnz / (X_sparse.shape[0] * X_sparse.shape[1])\n",
    "y_sparse = y_dense\n",
    "results_dense = evaluate_with_criteria_dense(X_dense, y_dense, methods_dense)\n",
    "results_sparse = evaluate_with_criteria_sparse(X_sparse, y_sparse, methods_sparse)\n",
    "\n",
    "display_results_table(results_dense)\n",
    "display_results_table(results_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17c7760",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense, y_dense, _ = generate_synthetic_dataset(n_samples=1000, n_features=500000, type='dense')\n",
    "\n",
    "X_sparse_raw = X_dense.copy()\n",
    "threshold = np.percentile(np.abs(X_sparse_raw), 99)\n",
    "X_sparse_raw[np.abs(X_sparse_raw) < threshold] = 0\n",
    "X_sparse = csr_matrix(X_sparse_raw)\n",
    "density = 100 * X_sparse.nnz / (X_sparse.shape[0] * X_sparse.shape[1])\n",
    "y_sparse = y_dense\n",
    "results_dense = evaluate_with_criteria_dense(X_dense, y_dense, methods_dense)\n",
    "results_sparse = evaluate_with_criteria_sparse(X_sparse, y_sparse, methods_sparse)\n",
    "\n",
    "display_results_table(results_dense)\n",
    "display_results_table(results_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense, y_dense, _ = generate_synthetic_dataset(n_samples=1000, n_features=100000, type='dense')\n",
    "\n",
    "X_sparse_raw = X_dense.copy()\n",
    "threshold = np.percentile(np.abs(X_sparse_raw), 99)\n",
    "X_sparse_raw[np.abs(X_sparse_raw) < threshold] = 0\n",
    "X_sparse = csr_matrix(X_sparse_raw)\n",
    "density = 100 * X_sparse.nnz / (X_sparse.shape[0] * X_sparse.shape[1])\n",
    "y_sparse = y_dense\n",
    "results_dense = evaluate_with_criteria_dense(X_dense, y_dense, methods_dense, C=0.001)\n",
    "results_sparse = evaluate_with_criteria_sparse(X_sparse, y_sparse, methods_sparse, C=0.001)\n",
    "\n",
    "display_results_table(results_dense)\n",
    "display_results_table(results_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d8be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense, y_dense, _ = generate_synthetic_dataset(n_samples=1000, n_features=100000, type='dense')\n",
    "\n",
    "X_sparse_raw = X_dense.copy()\n",
    "threshold = np.percentile(np.abs(X_sparse_raw), 99)\n",
    "X_sparse_raw[np.abs(X_sparse_raw) < threshold] = 0\n",
    "X_sparse = csr_matrix(X_sparse_raw)\n",
    "density = 100 * X_sparse.nnz / (X_sparse.shape[0] * X_sparse.shape[1])\n",
    "y_sparse = y_dense\n",
    "results_dense = evaluate_with_criteria_dense(X_dense, y_dense, methods_dense, C=100)\n",
    "results_sparse = evaluate_with_criteria_sparse(X_sparse, y_sparse, methods_sparse, C=100)\n",
    "\n",
    "display_results_table(results_dense)\n",
    "display_results_table(results_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense, y_dense, _ = generate_synthetic_dataset(n_samples=1000, n_features=100000, type='dense')\n",
    "\n",
    "X_sparse_raw = X_dense.copy()\n",
    "threshold = np.percentile(np.abs(X_sparse_raw), 99)\n",
    "X_sparse_raw[np.abs(X_sparse_raw) < threshold] = 0\n",
    "X_sparse = csr_matrix(X_sparse_raw)\n",
    "density = 100 * X_sparse.nnz / (X_sparse.shape[0] * X_sparse.shape[1])\n",
    "y_sparse = y_dense\n",
    "results_dense = evaluate_with_criteria_dense(X_dense, y_dense, methods_dense, tol=1e-4)\n",
    "results_sparse = evaluate_with_criteria_sparse(X_sparse, y_sparse, methods_sparse, tol=1e-4)\n",
    "\n",
    "display_results_table(results_dense)\n",
    "display_results_table(results_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5035bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense, y_dense, _ = generate_synthetic_dataset(n_samples=1000, n_features=100000, type='dense')\n",
    "\n",
    "X_sparse_raw = X_dense.copy()\n",
    "threshold = np.percentile(np.abs(X_sparse_raw), 99)\n",
    "X_sparse_raw[np.abs(X_sparse_raw) < threshold] = 0\n",
    "X_sparse = csr_matrix(X_sparse_raw)\n",
    "density = 100 * X_sparse.nnz / (X_sparse.shape[0] * X_sparse.shape[1])\n",
    "y_sparse = y_dense\n",
    "results_dense = evaluate_with_criteria_dense(X_dense, y_dense, methods_dense, tol=1e-6)\n",
    "results_sparse = evaluate_with_criteria_sparse(X_sparse, y_sparse, methods_sparse, tol=1e-6)\n",
    "\n",
    "display_results_table(results_dense)\n",
    "display_results_table(results_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba27194",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense, y_dense, _ = generate_synthetic_dataset(n_samples=1000, n_features=100000, type='dense')\n",
    "\n",
    "X_sparse_raw = X_dense.copy()\n",
    "threshold = np.percentile(np.abs(X_sparse_raw), 99)\n",
    "X_sparse_raw[np.abs(X_sparse_raw) < threshold] = 0\n",
    "X_sparse = csr_matrix(X_sparse_raw)\n",
    "density = 100 * X_sparse.nnz / (X_sparse.shape[0] * X_sparse.shape[1])\n",
    "y_sparse = y_dense\n",
    "results_dense = evaluate_with_criteria_dense(X_dense, y_dense, methods_dense, tol=1e-8)\n",
    "results_sparse = evaluate_with_criteria_sparse(X_sparse, y_sparse, methods_sparse, tol=1e-8)\n",
    "\n",
    "display_results_table(results_dense)\n",
    "display_results_table(results_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "y = 2 * (y - 0.5)  \n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "results = evaluate_with_criteria_dense(X, y, methods_dense, max_iter=1000)\n",
    "\n",
    "plot_convergence(results)\n",
    "print(len(X))\n",
    "print(len(X[0]))\n",
    "display_results_table(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc']\n",
    "data = fetch_20newsgroups(subset='train', categories=categories)\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=100000,\n",
    "    stop_words='english',\n",
    "    min_df=1\n",
    ")\n",
    "X = vectorizer.fit_transform(data.data)  \n",
    "\n",
    "y = data.target\n",
    "y = 2 * y - 1  \n",
    "\n",
    "X = X[:1000]\n",
    "y = y[:1000]\n",
    "\n",
    "d = X.nnz / (X.shape[0] * X.shape[1])\n",
    "\n",
    "results = evaluate_with_criteria_sparse(X, y, methods_sparse, max_iter=1000)\n",
    "\n",
    "display_results_table(results)\n",
    "plot_convergence(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c4a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence(results):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "    colors = prop_cycle.by_key()['color']\n",
    "    extended_colors = plt.get_cmap('tab20').colors  \n",
    "\n",
    "    for idx, res in enumerate(results):\n",
    "        label = f\"{res['Method']} - {res['Criterion']}\"\n",
    "        iters = list(range(1, len(res['Log']) + 1))\n",
    "        color = extended_colors[idx % len(extended_colors)]  \n",
    "        plt.plot(iters, res['Log'], label=label, color=color, linewidth=2)\n",
    "\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.xlim(0, 100)\n",
    "    plt.ylabel(\"Stopping criterion (log)\")\n",
    "    plt.title(\"Convergence of stopping criteria\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_convergence(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
